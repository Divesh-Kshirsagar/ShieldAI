"""
SHIELD AI — Phase 1: Data Ingestion & Real-Time Cleaning
=========================================================

Provides two Pathway tables consumed by downstream modules:

    cetp_stream        : Clean CETP inlet readings (floats, NA rows dropped).
    factory_raw_stream : All factory rows with BLACKOUT-tagged NA rows retained (v2).

Column naming approach
----------------------
Pathway 0.29.x requires Schema field names to exactly match CSV column headers.
Since the raw MPCB file (priya_cetp_i.csv) uses long headers with spaces and
hyphens, simulate_factories.py first creates:
    - data/cetp/cetp_clean.csv     (short Pythonic headers)
    - data/factories/factory_*.csv (short Pythonic headers)

Pathway reads from these preprocessed files. The raw file is never modified.

Cleaning rules
--------------
1. CETP stream  : Drop any row where cetp_inlet_cod is empty/null.
2. Factory stream: Retain null-cod rows but tag them status='BLACKOUT' (v2 anti-cheat).

Pathway streaming mode
----------------------
mode='streaming' tails the CSV directory and picks up new rows as they arrive,
replicating a live MPCB feed when historical CSVs are played back sequentially.
"""

from pathlib import Path

import pathway as pw

from src.constants import CETP_DATA_DIR, FACTORY_DATA_DIR


# ---------------------------------------------------------------------------
# Schema definitions
# ---------------------------------------------------------------------------

# NOTE: Field names must match cetp_clean.csv headers EXACTLY.
# cetp_clean.csv is generated by simulate_factories.preprocess_cetp().
class CETPSchema(pw.Schema):
    """Schema for data/cetp/cetp_clean.csv."""

    # NOTE: s_no is not primary_key — Pathway auto-generates unique IDs from
    # (file_path, row_position). Using s_no as PK would be fine for a single
    # CSV but we keep it consistent with FactorySchema (see below).
    s_no:             int
    time:             str
    cetp_inlet_cod:   float | None
    cetp_inlet_bod:   float | None
    cetp_inlet_ph:    float | None
    cetp_inlet_tss:   float | None
    cetp_outlet_cod:  float | None
    cetp_outlet_bod:  float | None
    cetp_outlet_ph:   float | None
    cetp_outlet_tss:  float | None


# NOTE: Field names must match factory_*.csv headers EXACTLY.
# Factory CSVs use clean names: s_no, time, factory_id, cod, bod, ph, tss.
class FactorySchema(pw.Schema):
    """Schema for data/factories/factory_*.csv."""

    # NOTE: s_no MUST NOT be primary_key here. All 4 factory CSVs share the
    # same s_no range (1-18781). If marked as PK, Pathway would see 4 × 18781
    # duplicate keys when reading the directory, causing 'duplicated entries'
    # errors in the asof/interval join engine. Pathway auto-generates unique
    # row IDs from (filename, row_position) instead, which are globally unique.
    s_no:        int
    time:        str
    factory_id:  str
    cod:         float | None
    bod:         float | None
    ph:          float | None
    tss:         float | None


# ---------------------------------------------------------------------------
# CETP stream
# ---------------------------------------------------------------------------

def load_cetp_stream(cetp_dir: str = CETP_DATA_DIR) -> pw.Table:
    """Read the preprocessed CETP CSV in streaming mode and return a clean inlet stream.

    Reads data/cetp/cetp_clean.csv (generated by simulate_factories.preprocess_cetp).
    Drops rows where cetp_inlet_cod is null (sensor gap / raw NA row).

    Args:
        cetp_dir: Directory containing cetp_clean.csv.

    Returns:
        Pathway Table matching CETPSchema with null-COD rows removed.
    """
    clean_path = Path(cetp_dir) / "cetp_clean.csv"
    if not clean_path.exists():
        raise FileNotFoundError(
            f"Preprocessed CETP file not found: '{clean_path}'.\n"
            "Run 'uv run python src/simulate_factories.py' first to generate it."
        )

    # NOTE: No value_columns / column_names kwargs — Pathway 0.29.x uses Schema
    # field names to match CSV headers directly. Headers in cetp_clean.csv
    # already match CETPSchema field names after preprocessing.
    raw: pw.Table = pw.io.csv.read(
        str(clean_path),        # read a single file, not a directory
        schema=CETPSchema,
        mode="streaming",
        autocommit_duration_ms=1_000,
    )

    # Filter: keep only rows where the CETP inlet COD sensor fired (non-null)
    cetp_clean: pw.Table = raw.filter(pw.this.cetp_inlet_cod.is_not_none())

    return cetp_clean


# ---------------------------------------------------------------------------
# Factory streams
# ---------------------------------------------------------------------------

def load_factory_streams(factory_dir: str = FACTORY_DATA_DIR) -> pw.Table:
    """Read all factory CSVs in the directory in streaming mode.

    Reads all factory_*.csv files in factory_dir. Each factory is already tagged
    with factory_id inside the CSV (written by simulate_factories.py).

    Retains null-COD rows tagged as status='BLACKOUT' for v2 anti-cheat logic.

    Args:
        factory_dir: Directory containing factory_A/B/C/D.csv.

    Returns:
        Pathway Table with FactorySchema columns plus a `status` string column.
    """
    if not Path(factory_dir).exists():
        raise FileNotFoundError(
            f"Factory data directory not found: '{factory_dir}'.\n"
            "Run 'uv run python src/simulate_factories.py' first."
        )

    # NOTE: Pathway reads all CSVs in the directory matching the schema.
    # factory_*.csv use clean headers (cod, bod, ph, tss) matching FactorySchema.
    raw: pw.Table = pw.io.csv.read(
        str(factory_dir),
        schema=FactorySchema,
        mode="streaming",
        autocommit_duration_ms=1_000,
    )

    # Tag each row: NORMAL (valid reading) vs BLACKOUT (sensor gap / NA)
    # NOTE: BLACKOUT rows are retained here — ingest does NOT drop them.
    # Phase 1 (backtrack.py) only uses NORMAL rows; anti_cheat.py (v2)
    # needs the full stream including BLACKOUT context.
    factory_with_status: pw.Table = raw.with_columns(
        status=pw.if_else(
            pw.this.cod.is_not_none(),
            "NORMAL",
            "BLACKOUT",
        )
    )

    return factory_with_status


def load_clean_factory_stream(factory_dir: str = FACTORY_DATA_DIR) -> pw.Table:
    """Return the factory stream with BLACKOUT (null-COD) rows removed.

    Used by Phase 1 aggregate → backtrack pipeline where only valid
    float COD readings participate in the asof_join.

    Args:
        factory_dir: Directory containing factory CSV files.

    Returns:
        Pathway Table with only NORMAL factory rows.
    """
    full = load_factory_streams(factory_dir)
    return full.filter(pw.this.cod.is_not_none())
